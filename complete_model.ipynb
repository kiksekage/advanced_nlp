{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "complete_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python37464bite82ff674e76f4e35b0c7582fef46bd24",
      "display_name": "Python 3.7.4 64-bit"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Z-O16QDJqpV",
        "outputId": "c8f60fa6-8e83-489d-f2bc-61a9d66f807d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# COLAB ONLY STUFF\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kOPdgThGlhf3",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, filepath):\n",
        "        cwd = os.getcwd()\n",
        "        self.basepath = filepath\n",
        "        try:\n",
        "            os.stat(self.basepath+\"/add_prim_split\")\n",
        "            os.stat(self.basepath+\"/few_shot_split\")\n",
        "            os.stat(self.basepath+\"/filler_split\")\n",
        "            os.stat(self.basepath+\"/length_split\")\n",
        "            os.stat(self.basepath+\"/simple_split\")\n",
        "            os.stat(self.basepath+\"/template_split\")\n",
        "        except Exception as e:\n",
        "            raise Exception(\"Path \"+filepath+\" doesnt seem to contain the required folders.\")\n",
        "\n",
        "    def load_1a(self):\n",
        "        train = self.file_loader(\"/simple_split/tasks_train_simple.txt\")\n",
        "        test = self.file_loader(\"/simple_split/tasks_test_simple.txt\")\n",
        "\n",
        "        return (np.asarray(train), np.asarray(test))\n",
        "\n",
        "    def load_1b(self):\n",
        "        percentile_dict = {}\n",
        "        splits = [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\"]\n",
        "\n",
        "        for percentile in splits:\n",
        "            train = self.file_loader(\"/simple_split/size_variations/tasks_train_simple_p{}.txt\".format(percentile))\n",
        "            test = self.file_loader(\"/simple_split/size_variations/tasks_test_simple_p{}.txt\".format(percentile))\n",
        "            \n",
        "            percentile_dict[percentile] = (np.asarray(train), np.asarray(test))\n",
        "            \n",
        "        return percentile_dict\n",
        "\n",
        "    def load_2(self):\n",
        "        train = self.file_loader(\"/length_split/tasks_train_length.txt\")\n",
        "        test = self.file_loader(\"/length_split/tasks_test_length.txt\")\n",
        "\n",
        "        return (np.asarray(train), np.asarray(test))\n",
        "\n",
        "    def load_3(self):\n",
        "        \"\"\"\n",
        "        loads the datasets for both parts of the experiment\n",
        "        the first part where both primitives appear without compositional commands\n",
        "        the second part where 'jump' primitive appears in\n",
        "        compositional commands of varying lengths\n",
        "        returns a dictionary of pairs all possible train/test sets\n",
        "        \"\"\"\n",
        "        data_dict = {}\n",
        "        nums = [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\"]\n",
        "        reps = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "        train = self.file_loader(\"/add_prim_split/tasks_train_addprim_jump.txt\")\n",
        "        test = self.file_loader(\"/add_prim_split/tasks_test_addprim_jump.txt\")\n",
        "        data_dict['jump'] = (np.asarray(train), np.asarray(test))\n",
        "\n",
        "        train = self.file_loader(\"/add_prim_split/tasks_train_addprim_turn_left.txt\")\n",
        "        test = self.file_loader(\"/add_prim_split/tasks_test_addprim_turn_left.txt\")\n",
        "        data_dict['lturn'] = (np.asarray(train), np.asarray(test))\n",
        "        \n",
        "        for num in nums:\n",
        "            for rep in reps:\n",
        "                train = self.file_loader(\"/add_prim_split/with_additional_examples/tasks_train_addprim_complex_jump_num{}_rep{}.txt\".format(num, rep))\n",
        "                test = self.file_loader(\"/add_prim_split/with_additional_examples/tasks_test_addprim_complex_jump_num{}_rep{}.txt\".format(num, rep))\n",
        "                \n",
        "                data_dict['jump_num{}_rep{}'.format(num, rep)] = (np.asarray(train), np.asarray(test))\n",
        "            \n",
        "        return data_dict\n",
        "\n",
        "    def file_loader(self, path):\n",
        "        sent_list = []\n",
        "        with open(self.basepath+path, \"r\") as f:\n",
        "                    for line in f:\n",
        "                        sent_list.append(line_splitter(line))\n",
        "        return sent_list\n",
        "\n",
        "    \n",
        "def line_splitter(sentence):\n",
        "    sent_list = sentence.split(\"OUT: \")\n",
        "    sent_list[0] = sent_list[0].strip(\"IN: \")\n",
        "    sent_list[1] = sent_list[1].strip(\"\\n\")\n",
        "\n",
        "    return sent_list\n",
        "\n",
        "# examples:\n",
        "# 1a :\n",
        "#   train, test = dl.load_1a()\n",
        "#   train[0][0] first train sentence, \"IN\"\n",
        "#   train[0][1] first train sentence, \"OUT\"\n",
        "# 1b :\n",
        "#   dict = dl.load_1b()\n",
        "#   train, test = dict[\"1\"] extract the 1 percentile sentences out, split into train and test\n",
        "#   train[0][0] first train sentence, \"OUT\"\n",
        "#   train[0][1] first train sentence, \"OUT\"\n",
        "#\n",
        "# all returns are numpy arrays\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FjVZyIyUlhgC",
        "colab": {}
      },
      "source": [
        "#from data_loader import DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Input:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"SOS\": SOS_token, \"EOS\": EOS_token}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "\n",
        "class Output:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"SOS\": SOS_token, \"EOS\": EOS_token}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "        \n",
        "def get_embedding(word, lookup_dict, embeds):\n",
        "    tensor = torch.tensor([lookup_dict[word]], dtype=torch.long)\n",
        "    return embeds(tensor)\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair, input_lang, output_lang):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, output_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pvsGAjCVlhgM",
        "colab": {}
      },
      "source": [
        "#from data_loader import *\n",
        "#from embeddings import *\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.0, layers=1, mode='RNN'):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.layers = layers\n",
        "        self.mode = mode\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        self.hidden_layer = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.layers, dropout=self.dropout_p)\n",
        "\n",
        "        if self.mode == 'LSTM':\n",
        "        \tself.hidden_layer = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.layers, dropout=self.dropout_p)\n",
        "        elif self.mode == 'GRU':\n",
        "        \tself.hidden_layer = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.layers, dropout=self.dropout_p)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        output, hidden = self.hidden_layer(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(self.layers, 1, self.hidden_size, device=device)\n",
        "        nn.init.xavier_uniform_(hidden, gain=nn.init.calculate_gain('relu'))\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, max_length, dropout_p=0.0, layers=1, attention=False, mode='RNN'):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.layers = layers\n",
        "        self.max_length = max_length\n",
        "        self.attention = attention\n",
        "        self.mode = mode\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        if self.attention:\n",
        "\t        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "\t        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "\n",
        "        self.hidden_layer = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.layers, dropout=self.dropout_p)\n",
        "\n",
        "        if self.mode == 'LSTM':\n",
        "        \tself.hidden_layer = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.layers, dropout=self.dropout_p)\n",
        "        elif self.mode == 'GRU':\n",
        "        \tself.hidden_layer = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.layers, dropout=self.dropout_p)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs=None):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if self.attention:\n",
        "          if self.mode==\"LSTM\":\n",
        "            attn_weights = F.softmax(self.attn(torch.cat((output[0], hidden[0][0]), 1)), dim=1)   \n",
        "          else:\n",
        "            attn_weights = F.softmax(self.attn(torch.cat((output[0], hidden[0]), 1)), dim=1)   \n",
        "          attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
        "          output = torch.cat((output[0], attn_applied[0]), 1)\n",
        "          output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.hidden_layer(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(self.layers, 1, self.hidden_size, device=device)\n",
        "        nn.init.xavier_uniform_(hidden, gain=nn.init.calculate_gain('relu'))\n",
        "        return hidden\n",
        "\n",
        "def train(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, clipping_value=5):\n",
        "    encoder_hidden1 = encoder.initHidden()\n",
        "    encoder_hidden2 = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    output_length = output_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        if encoder.mode == 'LSTM':\n",
        "            encoder_output, (encoder_hidden1, encoder_hidden2) = encoder(input_tensor[ei], (encoder_hidden1, encoder_hidden2))\n",
        "        else: \n",
        "            encoder_output, encoder_hidden1 = encoder(input_tensor[ei], encoder_hidden1)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden1 = encoder_hidden1\n",
        "    decoder_hidden2 = encoder_hidden2\n",
        "\n",
        "    forcing = random.random() > 0.5\n",
        "\n",
        "    if forcing:\n",
        "        for di in range(output_length):\n",
        "            if decoder.mode == 'LSTM':\n",
        "              decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2), encoder_outputs)\n",
        "            else:\n",
        "              decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden1, encoder_outputs)\n",
        "            \n",
        "            decoder_input = output_tensor[di]\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "\n",
        "            if decoder_input.item() == EOS_token:\n",
        "              break\n",
        "    else:\n",
        "        for di in range(output_length):\n",
        "            if decoder.mode == 'LSTM':\n",
        "              decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2), encoder_outputs)\n",
        "            else:\n",
        "              decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden1, encoder_outputs)\n",
        "            \n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "            \n",
        "            if decoder_input.item() == EOS_token:\n",
        "              break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clipping_value)\n",
        "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clipping_value)\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.item() / output_length\n",
        "\n",
        "    \n",
        "def trainIters(encoder, decoder, train_data, input_lang, output_lang, max_length, learning_rate=0.001):\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    losses = []\n",
        "    print(train_data.shape[0])\n",
        "    print_loss_total = 0\n",
        "\n",
        "    for iter in range(train_data.shape[0]):\n",
        "        training_pair = tensorsFromPair(train_data[iter], input_lang, output_lang)\n",
        "        input_tensor = training_pair[0]\n",
        "        output_tensor = training_pair[1]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            input_tensor = input_tensor.cuda()\n",
        "            output_tensor = output_tensor.cuda()\n",
        "        \n",
        "        loss = train(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % 1000 == 0:\n",
        "            print_loss_avg = print_loss_total / 500\n",
        "            losses.append(print_loss_avg)\n",
        "            print(iter)\n",
        "            print(print_loss_avg)\n",
        "            print_loss_total = 0\n",
        "\n",
        "    return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5ZlSSM1JlhgW",
        "colab": {}
      },
      "source": [
        "def train_and_save(train_data, train_in, train_out, model, dropout, att, layers, model_name, file_prefix, hidden_units=200, MAX_LENGTH=100):\n",
        "    encoder = Encoder(train_in.n_words, hidden_units, layers=layers, mode=model, dropout_p=dropout)\n",
        "    decoder = Decoder(hidden_units, train_out.n_words, layers=layers, max_length=MAX_LENGTH, mode=model, dropout_p=dropout, attention=att)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        encoder.cuda()\n",
        "        decoder.cuda()\n",
        "\n",
        "    losses = trainIters(encoder, decoder, train_data, train_in, train_out, MAX_LENGTH)\n",
        "    plt.plot(losses)\n",
        "    plt.title(model+'_layers='+str(layers)+'_drop='+str(dropout)+'_attention='+str(att))\n",
        "    plt.xlabel('iterations')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()\n",
        "    torch.save(encoder.state_dict(), file_prefix+model_name+\"_encoder.pt\")\n",
        "    torch.save(decoder.state_dict(), file_prefix+model_name+\"_decoder.pt\")\n",
        "\n",
        "def load_models(train_in_nwords, train_out_nwords, hidden_size, layers, mode, dropout_p, attention, file_location, model_name, max_length=100):\n",
        "    encoder = Encoder(train_in_nwords, hidden_size, layers=layers, mode=mode, dropout_p=dropout_p)\n",
        "    encoder.load_state_dict(torch.load(file_location+model_name+\"_encoder.pt\"))\n",
        "    encoder.eval()\n",
        "\n",
        "    decoder = Decoder(hidden_size, train_out_nwords, max_length, layers=layers, mode=mode, dropout_p=dropout_p, attention=attention)\n",
        "    decoder.load_state_dict(torch.load(file_location+model_name+\"_decoder.pt\"))\n",
        "    decoder.eval()\n",
        "\n",
        "    return encoder, decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OMnLV4Yllhgh",
        "colab": {}
      },
      "source": [
        "#from data_loader import *\n",
        "#from embeddings import *\n",
        "#from layers_attempt import *\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, train_in, train_out, max_length=100):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(train_in, sentence)\n",
        "    if torch.cuda.is_available():\n",
        "      input_tensor = input_tensor.cuda()\n",
        "      encoder.cuda()\n",
        "      decoder.cuda()\n",
        "\n",
        "    input_length = input_tensor.size()[0]\n",
        "    encoder_hidden1 = torch.zeros(encoder.layers, 1, encoder.hidden_size, device=device)\n",
        "    encoder_hidden2 = torch.zeros(encoder.layers, 1, encoder.hidden_size, device=device)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      if encoder.mode == \"LSTM\":\n",
        "        encoder_output, (encoder_hidden1, encoder_hidden2) = encoder(input_tensor[ei],(encoder_hidden1, encoder_hidden2))\n",
        "      else:\n",
        "        encoder_output, encoder_hidden1 = encoder(input_tensor[ei], encoder_hidden1)\n",
        "      encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden1 = encoder_hidden1\n",
        "    decoder_hidden2 = encoder_hidden2\n",
        "\n",
        "    decoded_words = []\n",
        "    \n",
        "    for di in range(max_length):\n",
        "      if decoder.mode == \"LSTM\":\n",
        "        decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2), encoder_outputs)\n",
        "      else:\n",
        "        decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden1, encoder_outputs)\n",
        "      \n",
        "      topv, topi = decoder_output.data.topk(1) \n",
        "      \n",
        "      if topi.item() == EOS_token:\n",
        "        break\n",
        "      else:\n",
        "        decoded_words.append(train_out.index2word[topi.item()])\n",
        "      \n",
        "      decoder_input = topi.squeeze().detach()\n",
        "\n",
        "    return decoded_words\n",
        "\n",
        "def evaluateIters(test_data, encoder, decoder, train_in, train_out):\n",
        "    hit = 0\n",
        "    miss = 0\n",
        "    iters = 0\n",
        "    hit_idx = []\n",
        "    miss_idx = []\n",
        "\n",
        "    for idx, test_point in enumerate(test_data):\n",
        "        pred_list = evaluate(encoder, decoder, test_point[0], train_in, train_out)\n",
        "        pred = \" \".join(pred_list)\n",
        "        if pred == test_point[1]:\n",
        "            hit += 1\n",
        "            hit_idx.append(idx)\n",
        "        else:\n",
        "            miss += 1\n",
        "            miss_idx.append(idx)\n",
        "        iters += 1\n",
        "\n",
        "        if iters % 100 == 0:\n",
        "            print(iters)\n",
        "            print(hit)\n",
        "\n",
        "    return hit, hit_idx, miss, miss_idx\n",
        "\n",
        "def evaluate_and_save(test_data, model_name, save_file, encoder, decoder, train_in, train_out):\n",
        "    print(encoder.hidden_size)\n",
        "    hit, hit_idx, miss, miss_idx = evaluateIters(test_data, encoder, decoder, train_in, train_out)\n",
        "    acc = 1-miss/len(test_data)\n",
        "\n",
        "    with open(\"/content/drive/My Drive/Colab Notebooks/models/\"+save_file, 'a') as f:\n",
        "        f.write(\"Model name: \" + model_name + \"\\n\")\n",
        "        f.write(\"Hits: \" + str(hit) + \"\\n\")\n",
        "        f.write(\"Miss: \" + str(miss) + \"\\n\")\n",
        "        f.write(\"Accuracy: \" + str(acc) + \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iu8aANmvlhgy",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#USED IN COLAB\n",
        "dl = DataLoader(\"/content/drive/My Drive/Colab Notebooks/SCAN\")\n",
        "\n",
        "#USED ON OWN PC\n",
        "#dl = DataLoader(\"SCAN\")\n",
        "\n",
        "#MAX_LENGTH = max([len(x[0].split()) for x in train_data]) + 1\n",
        "MAX_LENGTH = 100\n",
        "\n",
        "#DATA LOADING AND LANGUAGE CREATION, DIFFERS BETWEEN EXERCISES\n",
        "_, test_data = dl.load_2()\n",
        "\n",
        "test_in = Input(\"test_input\")\n",
        "test_out = Output(\"test_output\")\n",
        "\n",
        "for datapoint in test_data:\n",
        "        test_in.addSentence(datapoint[0])\n",
        "        test_out.addSentence(datapoint[1])\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10, 6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OkCCzKTN2zUU",
        "outputId": "0d705c42-a925-4888-96ee-fc45855e26ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from os import path\n",
        "print(path.exists(\"/content/drive/My Drive/Colab Notebooks/models/\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MS4Eo3brlhg6",
        "outputId": "af16b42a-c27c-45b6-d643-442eb31835fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "file_location = \"/content/drive/My Drive/Colab Notebooks/models/\"\n",
        "hidden_units=200\n",
        "model='LSTM'\n",
        "model_name = \"2nd_LSTM_200_dim_2_layer_no_att_drop\"\n",
        "\n",
        "for i in range(1, 2):\n",
        "\n",
        "    train_data, _ = dl.load_2()\n",
        "\n",
        "    train_in = Input(\"train_input\")\n",
        "    train_out = Output(\"train_output\")\n",
        "\n",
        "    for datapoint in train_data:\n",
        "        train_in.addSentence(datapoint[0])\n",
        "        train_out.addSentence(datapoint[1])\n",
        "\n",
        "    train_data = train_data[np.random.choice(train_data.shape[0], 100000, replace=True), :]\n",
        "\n",
        "    train_and_save(train_data, train_in, train_out, model, 0.5, False, 2, model_name+str(i), file_location, hidden_units=hidden_units)\n",
        "    encoder, decoder = load_models(train_in.n_words, train_out.n_words, hidden_units, 2, model, 0.5, False, file_location, model_name+str(i))\n",
        "    evaluate_and_save(test_data, model_name+str(i), model_name+str(i)+\".txt\", encoder, decoder, train_in, train_out)\n",
        "    print(\"################### ITERATION \" +str(i) +\" DONE ###################\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n",
            "0\n",
            "0.004147333526611329\n",
            "1000\n",
            "2.6785910911880695\n",
            "2000\n",
            "1.7166558382885686\n",
            "3000\n",
            "1.2240471660286063\n",
            "4000\n",
            "1.005243717809581\n",
            "5000\n",
            "0.8188051326930014\n",
            "6000\n",
            "0.7099622021674286\n",
            "7000\n",
            "0.6133371809163967\n",
            "8000\n",
            "0.5236726616478136\n",
            "9000\n",
            "0.39341044186867524\n",
            "10000\n",
            "0.3989638828327031\n",
            "11000\n",
            "0.29152751207908234\n",
            "12000\n",
            "0.27174735421777385\n",
            "13000\n",
            "0.2371609142997526\n",
            "14000\n",
            "0.21964153190646082\n",
            "15000\n",
            "0.20974840496395894\n",
            "16000\n",
            "0.19152547280235044\n",
            "17000\n",
            "0.17395064722901352\n",
            "18000\n",
            "0.10727524805269587\n",
            "19000\n",
            "0.12074514029496297\n",
            "20000\n",
            "0.11454199922322111\n",
            "21000\n",
            "0.1235444507799222\n",
            "22000\n",
            "0.10843405634463324\n",
            "23000\n",
            "0.0873169976049494\n",
            "24000\n",
            "0.11313246876265676\n",
            "25000\n",
            "0.0742612423882863\n",
            "26000\n",
            "0.1060049674292137\n",
            "27000\n",
            "0.08194089375508157\n",
            "28000\n",
            "0.05771988084140221\n",
            "29000\n",
            "0.05395078534254109\n",
            "30000\n",
            "0.05044805006637531\n",
            "31000\n",
            "0.047840785453457886\n",
            "32000\n",
            "0.0724914185103695\n",
            "33000\n",
            "0.05274599319702638\n",
            "34000\n",
            "0.04484800092529565\n",
            "35000\n",
            "0.0622410100200937\n",
            "36000\n",
            "0.03732803378269198\n",
            "37000\n",
            "0.07004939073036286\n",
            "38000\n",
            "0.03729015445730104\n",
            "39000\n",
            "0.03315496409556434\n",
            "40000\n",
            "0.03621626213707896\n",
            "41000\n",
            "0.02637472165525072\n",
            "42000\n",
            "0.048791768231719004\n",
            "43000\n",
            "0.022124051294933007\n",
            "44000\n",
            "0.016198327545274328\n",
            "45000\n",
            "0.016557059234452415\n",
            "46000\n",
            "0.027231710400517015\n",
            "47000\n",
            "0.028920748313284426\n",
            "48000\n",
            "0.01651224429995191\n",
            "49000\n",
            "0.022264106867512824\n",
            "50000\n",
            "0.03377952864176702\n",
            "51000\n",
            "0.03106073835511949\n",
            "52000\n",
            "0.044813268431981294\n",
            "53000\n",
            "0.027060044455781394\n",
            "54000\n",
            "0.010523299696205623\n",
            "55000\n",
            "0.007385775877430398\n",
            "56000\n",
            "0.02458615417098894\n",
            "57000\n",
            "0.021719684101889486\n",
            "58000\n",
            "0.025419730345615954\n",
            "59000\n",
            "0.009846501190767172\n",
            "60000\n",
            "0.02772416119592448\n",
            "61000\n",
            "0.02919175644360021\n",
            "62000\n",
            "0.010835294165344175\n",
            "63000\n",
            "0.023584249632755308\n",
            "64000\n",
            "0.03205881427392031\n",
            "65000\n",
            "0.0345467173514486\n",
            "66000\n",
            "0.05629052069846199\n",
            "67000\n",
            "0.02124995906023223\n",
            "68000\n",
            "0.012506817699269014\n",
            "69000\n",
            "0.012272217323139345\n",
            "70000\n",
            "0.008587258068630263\n",
            "71000\n",
            "0.015614480634480057\n",
            "72000\n",
            "0.00870558701245122\n",
            "73000\n",
            "0.013497323869541783\n",
            "74000\n",
            "0.007073718781696889\n",
            "75000\n",
            "0.03717295563215849\n",
            "76000\n",
            "0.014351754784130526\n",
            "77000\n",
            "0.0076056956439007695\n",
            "78000\n",
            "0.011699085795762608\n",
            "79000\n",
            "0.007910314415424566\n",
            "80000\n",
            "0.011030138208194663\n",
            "81000\n",
            "0.02531943521223717\n",
            "82000\n",
            "0.026988234478683093\n",
            "83000\n",
            "0.022764130668807645\n",
            "84000\n",
            "0.05147747452069583\n",
            "85000\n",
            "0.011055653180539034\n",
            "86000\n",
            "0.008746935475202553\n",
            "87000\n",
            "0.028125536208854624\n",
            "88000\n",
            "0.007356708279496699\n",
            "89000\n",
            "0.003557544736989666\n",
            "90000\n",
            "0.04407930087010212\n",
            "91000\n",
            "0.01931985668213747\n",
            "92000\n",
            "0.011739859022296248\n",
            "93000\n",
            "0.005006357263975749\n",
            "94000\n",
            "0.004444319785613992\n",
            "95000\n",
            "0.002059886711123572\n",
            "96000\n",
            "0.01486407270490407\n",
            "97000\n",
            "0.010894546611268588\n",
            "98000\n",
            "0.01311881189716689\n",
            "99000\n",
            "0.022802598805425508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIakCQsIiIiogFJwiIiIiIa8Ad0kHw+mdK+9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "100\n",
            "91\n",
            "200\n",
            "184\n",
            "300\n",
            "275\n",
            "400\n",
            "344\n",
            "500\n",
            "406\n",
            "600\n",
            "464\n",
            "700\n",
            "515\n",
            "800\n",
            "561\n",
            "900\n",
            "561\n",
            "1000\n",
            "561\n",
            "1100\n",
            "561\n",
            "1200\n",
            "561\n",
            "1300\n",
            "561\n",
            "1400\n",
            "561\n",
            "1500\n",
            "561\n",
            "1600\n",
            "561\n",
            "1700\n",
            "561\n",
            "1800\n",
            "561\n",
            "1900\n",
            "561\n",
            "2000\n",
            "561\n",
            "2100\n",
            "561\n",
            "2200\n",
            "561\n",
            "2300\n",
            "561\n",
            "2400\n",
            "561\n",
            "2500\n",
            "561\n",
            "2600\n",
            "561\n",
            "2700\n",
            "561\n",
            "2800\n",
            "561\n",
            "2900\n",
            "561\n",
            "3000\n",
            "561\n",
            "3100\n",
            "561\n",
            "3200\n",
            "561\n",
            "3300\n",
            "561\n",
            "3400\n",
            "561\n",
            "3500\n",
            "561\n",
            "3600\n",
            "561\n",
            "3700\n",
            "561\n",
            "3800\n",
            "561\n",
            "3900\n",
            "561\n",
            "################### ITERATION 1 DONE ###################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AGL-AUFPlhhE",
        "colab": {}
      },
      "source": [
        "#LOADING THE MODELS\n",
        "#encoder, decoder = load_models(train_in.n_words, train_out.n_words, hidden_units, 2, \"GRU\", 0.5, True, file_location, \"example\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "91ze_Dr3vjVd",
        "colab": {}
      },
      "source": [
        "train_data, _ = dl.load_2()\n",
        "\n",
        "train_in = Input(\"train_input\")\n",
        "train_out = Output(\"train_output\")\n",
        "\n",
        "for datapoint in train_data:\n",
        "    train_in.addSentence(datapoint[0])\n",
        "    train_out.addSentence(datapoint[1])\n",
        "\n",
        "file_location = \"/content/drive/My Drive/Colab Notebooks/models/\"\n",
        "hidden_units=200\n",
        "model='LSTM'\n",
        "model_name = \"2nd_LSTM_200_dim_2_layer_att_no_drop\"\n",
        "\n",
        "\n",
        "encoder, decoder = load_models(train_in.n_words, train_out.n_words, hidden_units, 2, model, 0.5, False, file_location, model_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ewBwqRolhhN",
        "colab": {}
      },
      "source": [
        "#EVALUATION OF MODEL\n",
        "actual_train_data, test_data = dl.load_2()\n",
        "hit, hit_idx, miss, miss_idx = evaluateIters(test_data, encoder, decoder, train_in, train_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "An1eUij2lhhd",
        "colab": {}
      },
      "source": [
        "#ACCURACY\n",
        "acc=1-miss/test_data.shape[0]\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HexSo94Alhhn",
        "colab": {}
      },
      "source": [
        "#SOME RANDOM PRINTING/EVALUATION VALIDATION\n",
        "idx = miss_idx[2]\n",
        "print(test_data[idx][0])\n",
        "print(len(evaluate(encoder, decoder, test_data[idx][0], train_in, train_out)))\n",
        "print(\" \".join(evaluate(encoder, decoder, test_data[idx][0], train_in, train_out)))\n",
        "print(len(test_data[idx][1].split()))\n",
        "print(test_data[idx][1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}