{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "initial_train_attempt_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, filepath):\n",
        "        cwd = os.getcwd()\n",
        "        self.basepath = filepath\n",
        "        try:\n",
        "            os.stat(self.basepath+\"/add_prim_split\")\n",
        "            os.stat(self.basepath+\"/few_shot_split\")\n",
        "            os.stat(self.basepath+\"/filler_split\")\n",
        "            os.stat(self.basepath+\"/length_split\")\n",
        "            os.stat(self.basepath+\"/simple_split\")\n",
        "            os.stat(self.basepath+\"/template_split\")\n",
        "        except Exception as e:\n",
        "            raise Exception(\"Path \"+filepath+\" doesnt seem to contain the required folders.\")\n",
        "\n",
        "    def load_1a(self):\n",
        "        train = self.file_loader(\"/simple_split/tasks_train_simple.txt\")\n",
        "        test = self.file_loader(\"/simple_split/tasks_test_simple.txt\")\n",
        "\n",
        "        return (np.asarray(train), np.asarray(test))\n",
        "\n",
        "    def load_1b(self):\n",
        "        percentile_dict = {}\n",
        "        splits = [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\"]\n",
        "\n",
        "        for percentile in splits:\n",
        "            train = self.file_loader(\"/simple_split/size_variations/tasks_train_simple_p{}.txt\".format(percentile))\n",
        "            test = self.file_loader(\"/simple_split/size_variations/tasks_test_simple_p{}.txt\".format(percentile))\n",
        "            \n",
        "            percentile_dict[percentile] = (np.asarray(train), np.asarray(test))\n",
        "            \n",
        "        return percentile_dict\n",
        "\n",
        "    def load_2(self):\n",
        "        train = self.file_loader(\"/length_split/tasks_train_length.txt\")\n",
        "        test = self.file_loader(\"/length_split/tasks_test_length.txt\")\n",
        "\n",
        "        return (np.asarray(train), np.asarray(test))\n",
        "\n",
        "    def load_3(self):\n",
        "        \"\"\"\n",
        "        loads the datasets for both parts of the experiment\n",
        "        the first part where both primitives appear without compositional commands\n",
        "        the second part where 'jump' primitive appears in\n",
        "        compositional commands of varying lengths\n",
        "        returns a dictionary of pairs all possible train/test sets\n",
        "        \"\"\"\n",
        "        data_dict = {}\n",
        "        nums = [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\"]\n",
        "        reps = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "        train = self.file_loader(\"/add_prim_split/tasks_train_addprim_jump.txt\")\n",
        "        test = self.file_loader(\"/add_prim_split/tasks_test_addprim_jump.txt\")\n",
        "        data_dict['jump'] = (np.asarray(train), np.asarray(test))\n",
        "\n",
        "        train = self.file_loader(\"/add_prim_split/tasks_train_addprim_turn_left.txt\")\n",
        "        test = self.file_loader(\"/add_prim_split/tasks_test_addprim_turn_left.txt\")\n",
        "        data_dict['lturn'] = (np.asarray(train), np.asarray(test))\n",
        "        \n",
        "        for num in nums:\n",
        "            for rep in reps:\n",
        "                train = self.file_loader(\"/add_prim_split/with_additional_examples/tasks_train_addprim_complex_jump_num{}_rep{}.txt\".format(num, rep))\n",
        "                test = self.file_loader(\"/add_prim_split/with_additional_examples/tasks_test_addprim_complex_jump_num{}_rep{}.txt\".format(num, rep))\n",
        "                \n",
        "                data_dict['jump_num{}_rep{}'.format(num, rep)] = (np.asarray(train), np.asarray(test))\n",
        "            \n",
        "        return data_dict\n",
        "\n",
        "    def file_loader(self, path):\n",
        "        sent_list = []\n",
        "        with open(self.basepath+path, \"r\") as f:\n",
        "                    for line in f:\n",
        "                        sent_list.append(line_splitter(line))\n",
        "        return sent_list\n",
        "\n",
        "    \n",
        "def line_splitter(sentence):\n",
        "    sent_list = sentence.split(\"OUT: \")\n",
        "    sent_list[0] = sent_list[0].strip(\"IN: \")\n",
        "    sent_list[1] = sent_list[1].strip(\"\\n\")\n",
        "\n",
        "    return sent_list\n",
        "\n",
        "# examples:\n",
        "# 1a :\n",
        "#   train, test = dl.load_1a()\n",
        "#   train[0][0] first train sentence, \"IN\"\n",
        "#   train[0][1] first train sentence, \"OUT\"\n",
        "# 1b :\n",
        "#   dict = dl.load_1b()\n",
        "#   train, test = dict[\"1\"] extract the 1 percentile sentences out, split into train and test\n",
        "#   train[0][0] first train sentence, \"OUT\"\n",
        "#   train[0][1] first train sentence, \"OUT\"\n",
        "#\n",
        "# all returns are numpy arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from data_loader import DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Input:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {EOS_token: \"EOS\"}\n",
        "        self.index2word = {}\n",
        "        self.n_words = 1  # Count SOS and EOS\n",
        "        #self.n_words = 0\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "class Output:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        #self.index2word = {}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "        #self.n_words = 0\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "\n",
        "        \n",
        "def get_embedding(word, lookup_dict, embeds):\n",
        "    tensor = torch.tensor([lookup_dict[word]], dtype=torch.long)\n",
        "    return embeds(tensor)\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair, input_lang, output_lang):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, output_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "100000\n0\n0.021006372239854604\n100\n1.7936736000264741\n200\n1.6317723615812922\n300\n1.4683492508953992\n400\n1.327637120878245\n500\n1.2735754318703056\n600\n1.2957731034088107\n700\n1.21741220196039\n800\n1.0303535042118126\n900\n1.0273131595203728\n1000\n0.9378885109147054\n1100\n0.9727492157588189\n1200\n0.7740695696355263\n1300\n0.8545121337997027\n1400\n0.8676959457699084\n1500\n0.7035560652148929\n1600\n0.6590683256382736\n1700\n0.6800176236549809\n1800\n0.7181776510703836\n1900\n0.6590087908662662\n2000\n0.5786020499518685\n2100\n0.5893913711755422\n2200\n0.4957056226121494\n2300\n0.5247464889327935\n2400\n0.6020320643930831\n2500\n0.4755667286560053\n2600\n0.4467348939526238\n2700\n0.4678752300019945\n2800\n0.40063126319120995\n2900\n0.44193447202151537\n3000\n0.4820828094032301\n3100\n0.4235209168090121\n3200\n0.3898991174863301\n3300\n0.4521052464331314\n3400\n0.37410309596485225\n3500\n0.43434033320041904\n3600\n0.4485664719636244\n3700\n0.43670671743876527\n3800\n0.41524831462497863\n3900\n0.3516833120181532\n4000\n0.3574706847594107\n4100\n0.46619769495730123\n4200\n0.39577547232594895\n4300\n0.35642794501691866\n4400\n0.3014506715401934\n4500\n0.4224589253303719\n4600\n0.34634055098142064\n4700\n0.35104192392606826\n4800\n0.2527667013570111\n4900\n0.251409732394714\n5000\n0.343112802418902\n5100\n0.249576723546862\n5200\n0.2832876336968462\n5300\n0.29285872598106527\n5400\n0.2769100125152222\n5500\n0.33340353359899333\n5600\n0.22621063577470416\n5700\n0.25845009231683547\n5800\n0.23422841412116605\n5900\n0.26856790331472735\n6000\n0.3313479551311859\n6100\n0.27109080419079606\n6200\n0.281632796144622\n6300\n0.18703372698593804\n6400\n0.22506652800552213\n6500\n0.2412626916231741\n6600\n0.21386871478990202\n6700\n0.18568072105782335\n6800\n0.2801861127098879\n6900\n0.1585109367023943\n7000\n0.19916269114060575\n7100\n0.24641864044712494\n7200\n0.12841721666891875\n7300\n0.15679395816631955\n7400\n0.18316739961108555\n7500\n0.16077475312845432\n7600\n0.2285105585485883\n7700\n0.13862526970091799\n7800\n0.16014193294145432\n7900\n0.28171144050567454\n8000\n0.14596224127072754\n8100\n0.19402691016880258\n8200\n0.16112638090185338\n8300\n0.22788705023609665\n8400\n0.2720789458701674\n8500\n0.26056016587887076\n8600\n0.11091679916424421\n8700\n0.12266093158710395\n8800\n0.16327613159760243\n8900\n0.14406087619464913\n9000\n0.1679817331083048\n9100\n0.17343674895849628\n9200\n0.1488057503937865\n9300\n0.10686536932648907\n9400\n0.12078668538926865\n9500\n0.17424551386615114\n9600\n0.177558992302831\n9700\n0.10899702685676232\n9800\n0.16377282343929206\n9900\n0.12129245335795343\n10000\n0.1606755897714632\n10100\n0.09908718193355318\n10200\n0.15685863360592275\n10300\n0.15230854253207182\n10400\n0.12066054275985469\n10500\n0.13864523837470158\n10600\n0.13637334844122212\n10700\n0.1601871217846676\n10800\n0.0972103465182843\n10900\n0.10295433059627233\n11000\n0.0907263556680278\n11100\n0.09938617993512784\n11200\n0.08544059709847698\n11300\n0.0920524839173594\n11400\n0.10942777869114641\n11500\n0.08515024048915538\n11600\n0.16065119202847733\n11700\n0.08851771302068777\n11800\n0.15492972550799658\n11900\n0.11544153240168965\n12000\n0.06844577145789504\n12100\n0.13189911322861683\n12200\n0.0780440486667422\n12300\n0.0801795101952397\n12400\n0.07014812676944109\n12500\n0.12146609633328805\n12600\n0.10408909954528729\n12700\n0.0765396828379457\n12800\n0.05225884270130418\n12900\n0.11255411710238858\n13000\n0.08816019880582406\n13100\n0.09011649589049466\n13200\n0.10907387823952783\n13300\n0.0988925201172332\n13400\n0.10416569471595734\n13500\n0.06015023609129621\n13600\n0.13921182802256363\n13700\n0.07020221847819813\n13800\n0.0820437915139647\n13900\n0.08309670888769086\n14000\n0.08102075353185878\n14100\n0.07737019920386333\n14200\n0.06589545749883617\n14300\n0.0786469403894385\n14400\n0.0974754148802968\n14500\n0.06718102415948173\n14600\n0.13597774639565194\n14700\n0.07056182139812513\n14800\n0.10190878330673192\n14900\n0.08310439108710384\n15000\n0.0710693141876138\n15100\n0.13111534957045723\n15200\n0.08101527766298591\n15300\n0.05028291360745283\n15400\n0.07148740188306629\n15500\n0.04975166199209032\n15600\n0.09642483344634518\n15700\n0.0606024469109194\n15800\n0.08887674380960751\n15900\n0.08275109779899863\n16000\n0.05437165290638294\n16100\n0.06866851899177145\n16200\n0.06575951251875649\n16300\n0.060160890377983514\n16400\n0.04744138147638721\n16500\n0.07738462018435185\n16600\n0.05307746376542603\n16700\n0.0630357332534349\n16800\n0.059134008481414764\n16900\n0.08690787998909942\n17000\n0.053790911322249974\n17100\n0.09415424809266389\n17200\n0.1493920207786434\n17300\n0.06556267590863764\n17400\n0.04919658452778601\n17500\n0.059457041006451716\n17600\n0.07825590897928485\n17700\n0.0459737606950065\n17800\n0.05479550012806919\n17900\n0.05215928823867058\n18000\n0.08274379753629629\n18100\n0.12684593478527\n18200\n0.05112563808922073\n18300\n0.11088687005698648\n18400\n0.10910788861892153\n18500\n0.046602191138477134\n18600\n0.09521470041260605\n18700\n0.08726760651693366\n18800\n0.038759682361183045\n18900\n0.07107397671840177\n19000\n0.08744259300950395\n19100\n0.09141708522893532\n19200\n0.07367887053568348\n19300\n0.04896977964224211\n19400\n0.07388323034329063\n19500\n0.04709493274392094\n19600\n0.06574215516299231\n19700\n0.04755120546019571\n19800\n0.038292356495438995\n19900\n0.07139941172169734\n20000\n0.05944223337738418\n20100\n0.03763211042871767\n20200\n0.04625075198328035\n20300\n0.061564531261794155\n20400\n0.0668235519426655\n20500\n0.04317838843335002\n20600\n0.05944689259631785\n20700\n0.035833798613200615\n20800\n0.04532435452176348\n20900\n0.04046299967170665\n21000\n0.10722433313809582\n21100\n0.04578926096856233\n21200\n0.031124084287796495\n21300\n0.05907405647352803\n21400\n0.0418437588704901\n21500\n0.038195402765376474\n21600\n0.06296771938203603\n21700\n0.06435681977263222\n21800\n0.03463812114710809\n21900\n0.03952217293399708\n22000\n0.05882508241535257\n22100\n0.15182463446334687\n22200\n0.04975400522283808\n22300\n0.0488968736595662\n22400\n0.044786074213318566\n22500\n0.03339311518271039\n22600\n0.04161744979155839\n22700\n0.032543376692149996\n22800\n0.03869745157091933\n22900\n0.05324917363638795\n23000\n0.05652700799393747\n23100\n0.05229697260864796\n23200\n0.057737892216342665\n23300\n0.03927365081871941\n23400\n0.026813784692606576\n23500\n0.03216585722728458\n23600\n0.03434699390328155\n23700\n0.03279182529710606\n23800\n0.02901735079112462\n23900\n0.04083770619584401\n24000\n0.032300318248979346\n24100\n0.031413682643180396\n24200\n0.06589217491606654\n24300\n0.03101163111405495\n24400\n0.028081849638492293\n24500\n0.06477367810507043\n24600\n0.043221201351027444\n24700\n0.02054310259504536\n24800\n0.027696856171601655\n24900\n0.033932266891824325\n25000\n0.06373302732712838\n25100\n0.018274768204986195\n25200\n0.05739510525072095\n25300\n0.029240370314739045\n25400\n0.04884245302668537\n25500\n0.034055839494821195\n25600\n0.04330319094833477\n25700\n0.04622867198528517\n25800\n0.0213098311061153\n25900\n0.034132404931067464\n26000\n0.05408504561625356\n26100\n0.024652309161453966\n26200\n0.02637066641043243\n26300\n0.02059566714349825\n26400\n0.05702662837235597\n26500\n0.028966605679940395\n26600\n0.06205950236122173\n26700\n0.03160679458750605\n26800\n0.025562741280368586\n26900\n0.036298582233633664\n27000\n0.03160855888569054\n27100\n0.04612402130621054\n27200\n0.015494398384641226\n27300\n0.02641267761991804\n27400\n0.01751938642156275\n27500\n0.03384021610473843\n27600\n0.04765012555660694\n27700\n0.022821579179421018\n27800\n0.01835748109409479\n27900\n0.043704454558452926\n28000\n0.039148068933689426\n28100\n0.05795366302523031\n28200\n0.025066215019625266\n28300\n0.050881693991334354\n28400\n0.051284800846908486\n28500\n0.016589926826465293\n28600\n0.025162297212706897\n28700\n0.03702547501699869\n28800\n0.03009493429913722\n28900\n0.018048371292231934\n29000\n0.07436854038922115\n29100\n0.027405090141558862\n29200\n0.032447582739320364\n29300\n0.01008228057875264\n29400\n0.0294143739034621\n29500\n0.051954001468257086\n29600\n0.029677793466869697\n29700\n0.15338386202301593\n29800\n0.027520790181416135\n29900\n0.04894545127697118\n30000\n0.013604516134866306\n30100\n0.0331612328835012\n30200\n0.021663618812739406\n30300\n0.01682315982806288\n30400\n0.04609226152110134\n30500\n0.05113639363553469\n30600\n0.03023609875661971\n30700\n0.04612472676026151\n30800\n0.13128543623083172\n30900\n0.046882712203896074\n31000\n0.0723188311964056\n31100\n0.012098264614113976\n31200\n0.04047631338001214\n31300\n0.09435796710961489\n31400\n0.07068067344341421\n31500\n0.01403458802399142\n31600\n0.06400195948791257\n31700\n0.028552220005167852\n31800\n0.02845355001579239\n31900\n0.026070600612270563\n32000\n0.01937259434782186\n32100\n0.043565214474041006\n32200\n0.050578232700245\n32300\n0.04577652733734938\n32400\n0.02673127299336976\n32500\n0.012338896768174448\n32600\n0.026483805231287648\n32700\n0.017143790506466142\n32800\n0.12396233693310134\n32900\n0.013953480467832598\n33000\n0.02392673092536378\n33100\n0.02811352656524901\n33200\n0.020201058396278077\n33300\n0.020055943651231974\n33400\n0.03597836939308947\n33500\n0.02277864929222516\n33600\n0.03013167724917798\n33700\n0.04112884777335923\n33800\n0.01900325693139075\n33900\n0.029227587765659545\n34000\n0.025074166946903502\n34100\n0.022422066262712686\n34200\n0.04314394871653657\n34300\n0.035933235687243784\n34400\n0.018178691851409957\n34500\n0.0271286251721546\n34600\n0.025449767123612653\n34700\n0.013697847981336685\n34800\n0.02549862969179343\n34900\n0.035512541009316674\n35000\n0.026801527309008866\n35100\n0.03921488110240851\n35200\n0.021283110534601364\n35300\n0.021395299099819173\n35400\n0.0705649211234286\n35500\n0.03925506805656151\n35600\n0.016829444125461668\n35700\n0.02094679385971194\n35800\n0.07638701254806135\n35900\n0.026728869570022195\n36000\n0.027684747399640556\n36100\n0.05993743997345838\n36200\n0.013605895887170061\n36300\n0.052916395232848856\n36400\n0.03761648723289318\n36500\n0.02611197346665251\n36600\n0.019900921856856844\n36700\n0.021383617665855864\n36800\n0.07193768071063528\n36900\n0.08093495054388013\n37000\n0.04684887182101244\n37100\n0.11504362771711352\n37200\n0.05762550454148\n37300\n0.1132712738761873\n37400\n0.023907388665037624\n37500\n0.08839229230962829\n37600\n0.018003432788266535\n37700\n0.022956219811308808\n37800\n0.07261937743591683\n37900\n0.028377567000135828\n38000\n0.021144741010867434\n38100\n0.02177234379809766\n38200\n0.0399364665324491\n38300\n0.013482313753920441\n38400\n0.011706373796653123\n38500\n0.04889518252061153\n38600\n0.05643228233640258\n38700\n0.03571734298840318\n38800\n0.04445570389078986\n38900\n0.05255951401725821\n39000\n0.03306390479187118\n39100\n0.02830202166122352\n39200\n0.021817035140572306\n39300\n0.02178179255703856\n39400\n0.05282153499670189\n39500\n0.022862891920657106\n39600\n0.054327131726496204\n39700\n0.02264816723612233\n39800\n0.018250199557606487\n39900\n0.08378502413893514\n40000\n0.016033791046163513\n40100\n0.05030127536711837\n40200\n0.029861373026558568\n40300\n0.1341418723578442\n40400\n0.011051112800865267\n40500\n0.018743779467332997\n40600\n0.026512915598831358\n40700\n0.016907092372047947\n40800\n0.14532226460072742\n40900\n0.03371348998690862\n41000\n0.05992096890562638\n41100\n0.0873657247784498\n41200\n0.031192567534094585\n41300\n0.05502554475049257\n41400\n0.09928493721121097\n41500\n0.02410827886213215\n41600\n0.05329777324173837\n41700\n0.021015888809777672\n41800\n0.020451530983504485\n41900\n0.01314818171669661\n42000\n0.011883795411803904\n42100\n0.02956949157757057\n42200\n0.023681778846198324\n42300\n0.029570749439475033\n42400\n0.05809469638730218\n42500\n0.026184106764047782\n42600\n0.030777215682504484\n42700\n0.03520272943625821\n42800\n0.02122791872382704\n42900\n0.03894625957226701\n43000\n0.010284650796237187\n43100\n0.05428935478950418\n43200\n0.007503543933532019\n43300\n0.010847611167732554\n43400\n0.022726018881721006\n43500\n0.0184017375205094\n43600\n0.027506531828903388\n43700\n0.03356692040243379\n43800\n0.023581744414012954\n43900\n0.15169506867056046\n44000\n0.15270831450154504\n44100\n0.02459861678898437\n44200\n0.011193400979069838\n44300\n0.021632556955983963\n44400\n0.01145784721068004\n44500\n0.024219848638701653\n44600\n0.0420726463679145\n44700\n0.026796969637380142\n44800\n0.013909975766450986\n44900\n0.060013493797644195\n45000\n0.049306031809014064\n45100\n0.03464321106448787\n45200\n0.01714107936321294\n45300\n0.08731796194439745\n45400\n0.017197146375373215\n45500\n0.04829233782850505\n45600\n0.03867138199608475\n45700\n0.04731158762773796\n45800\n0.04191528280157179\n45900\n0.022676460937317705\n46000\n0.07773821099417363\n46100\n0.02894363191146993\n46200\n0.13647022760102925\n46300\n0.03534585304619434\n46400\n0.014198876951533936\n46500\n0.028365115626919755\n46600\n0.026290216951323612\n46700\n0.014645402606946174\n46800\n0.024626102454817146\n46900\n0.015392051512816226\n47000\n0.029714494447246265\n47100\n0.010295972016347688\n47200\n0.019571209197643432\n47300\n0.01989671615585767\n47400\n0.020956697786976727\n47500\n0.01193680033574866\n47600\n0.02273019972300723\n47700\n0.05139936843929026\n47800\n0.01954085166954481\n47900\n0.012578574137291052\n48000\n0.02786847942385852\n48100\n0.03097581643972073\n48200\n0.01621937797128397\n48300\n0.022954847183799636\n48400\n0.013601552320443678\n48500\n0.01853784905521219\n48600\n0.01567586384994958\n48700\n0.024865916017427252\n48800\n0.01752135374161333\n48900\n0.023974175387038516\n49000\n0.01307944741066653\n49100\n0.019846726908148052\n"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#from data_loader import *\n",
        "#from embeddings import *\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class CustomLoss(torch.autograd.Function):  \n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        import ipdb; ipdb.set_trace()\n",
        "        #pass\n",
        "        return\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.0, layers=1, mode='RNN'):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.layers = layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        self.hidden_layer = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "        if mode == 'LSTM':\n",
        "        \tself.hidden_layer = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        elif mode == 'GRU':\n",
        "        \tself.hidden_layer = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        output, hidden = self.hidden_layer(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(self.layers, 1, self.hidden_size, device=device)\n",
        "        nn.init.xavier_uniform_(hidden, gain=nn.init.calculate_gain('relu'))\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, max_length, dropout_p=0.0, layers=1, attention=False, mode='RNN'):\n",
        "    \t#layers should be either 1 or 2\n",
        "    \t#in the latter case remember to pass a pair of hidden states!\n",
        "    \t#mode can be either 'LSTM', 'GRU' or 'RNN'\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.layers = layers\n",
        "        self.max_length = max_length\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        if self.attention:\n",
        "\t        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "\t        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "\n",
        "        self.hidden_layer = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "        if mode == 'LSTM':\n",
        "        \tself.hidden_layer = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        elif mode == 'GRU':\n",
        "        \tself.hidden_layer = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs=None):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if self.attention:\n",
        "\t        attn_weights = F.softmax(\n",
        "\t            self.attn(torch.cat((output[0], hidden[0]), 1)), dim=1)\n",
        "\t        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "\t                                 encoder_outputs.unsqueeze(0))\n",
        "\t        output = torch.cat((output[0], attn_applied[0]), 1)\n",
        "        \toutput = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.hidden_layer(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(self.layers, 1, self.hidden_size, device=device)\n",
        "        nn.init.xavier_uniform_(hidden, gain=nn.init.calculate_gain('relu'))\n",
        "        return hidden\n",
        "\n",
        "def train(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, clipping_value=5, mode='RNN'):\n",
        "    encoder_hidden1 = encoder.initHidden()\n",
        "    encoder_hidden2 = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    output_length = output_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        if mode == 'LSTM':\n",
        "            encoder_output, (encoder_hidden1, encoder_hidden2) = encoder(input_tensor[ei], (encoder_hidden1, encoder_hidden2))\n",
        "        else: \n",
        "            encoder_output, encoder_hidden1 = encoder(input_tensor[ei], encoder_hidden1)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden1 = encoder_hidden1\n",
        "    decoder_hidden2 = encoder_hidden2\n",
        "\n",
        "    forcing = random.random() > 0.5\n",
        "\n",
        "    if forcing:\n",
        "        for di in range(output_length):\n",
        "            if mode == 'LSTM':\n",
        "                decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2))\n",
        "            else:\n",
        "                decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden)\n",
        "            decoder_input = output_tensor[di]\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "    else:\n",
        "        for di in range(output_length):\n",
        "            if mode == 'LSTM':\n",
        "                decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2))\n",
        "            else:\n",
        "                decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden1, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "            \n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    #loss = CustomLoss\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clipping_value)\n",
        "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clipping_value)\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.item() / output_length\n",
        "\n",
        "    \n",
        "def trainIters(encoder, decoder, train_data, input_lang, output_lang, max_length, learning_rate=0.001, mode='RNN'):\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    losses = []\n",
        "    print(train_data.shape[0])\n",
        "    print_loss_total = 0\n",
        "\n",
        "    for iter in range(train_data.shape[0]):\n",
        "        training_pair = tensorsFromPair(train_data[iter], input_lang, output_lang)\n",
        "        input_tensor = training_pair[0]\n",
        "        output_tensor = training_pair[1]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            input_tensor = input_tensor.cuda()\n",
        "            output_tensor = output_tensor.cuda()\n",
        "        \n",
        "        loss = train(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, mode=mode)\n",
        "        losses.append(loss)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % 100 == 0:\n",
        "            print_loss_avg = print_loss_total / 100\n",
        "            print(iter)\n",
        "            print(print_loss_avg)\n",
        "            print_loss_total = 0\n",
        "\n",
        "    return losses\n",
        "\n",
        "dl = DataLoader(\"/content/drive/My Drive/Colab Notebooks/SCAN\")\n",
        "#dl = DataLoader(\"SCAN\")\n",
        "train_data, test_data = dl.load_1a()\n",
        "\n",
        "MAX_LENGTH = max([len(x[0].split()) for x in train_data]) + 1\n",
        "\n",
        "train_in = Input(\"train_input\")\n",
        "train_out = Output(\"train_output\")\n",
        "\n",
        "test_in = Input(\"test_input\")\n",
        "test_out = Output(\"test_output\")\n",
        "\n",
        "for datapoint in train_data:\n",
        "        train_in.addSentence(datapoint[0])\n",
        "        train_out.addSentence(datapoint[1])\n",
        "\n",
        "for datapoint in test_data:\n",
        "        test_in.addSentence(datapoint[0])\n",
        "        test_out.addSentence(datapoint[1])\n",
        "\n",
        "model = \"LSTM\"\n",
        "\n",
        "train_data = train_data[np.random.choice(train_data.shape[0], 100000, replace=True), :]\n",
        "\n",
        "encoder = Encoder(train_in.n_words, 200, layers=2, mode=model)\n",
        "decoder = Decoder(200, train_out.n_words, layers=2, max_length=MAX_LENGTH, mode=model)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "   encoder.cuda()\n",
        "   decoder.cuda()\n",
        "\n",
        "%time losses = trainIters(encoder, decoder, train_data, train_in, train_out, MAX_LENGTH, mode=model)\n",
        "print(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": "8"
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.save(encoder.state_dict(), \"encoder_test.pt\")\n",
        "torch.save(decoder.state_dict(), \"decoder_test.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "pxmS4rEHL366",
        "outputId": "7c144b71-43bf-454f-a369-df7b5bb776e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "62\n",
            "200\n",
            "132\n",
            "300\n",
            "205\n",
            "400\n",
            "275\n",
            "500\n",
            "342\n",
            "600\n",
            "414\n",
            "700\n",
            "481\n",
            "800\n",
            "552\n",
            "900\n",
            "627\n",
            "1000\n",
            "705\n",
            "1100\n",
            "781\n",
            "1200\n",
            "845\n",
            "1300\n",
            "920\n",
            "1400\n",
            "990\n",
            "1500\n",
            "1068\n",
            "1600\n",
            "1136\n",
            "1700\n",
            "1213\n",
            "1800\n",
            "1282\n",
            "1900\n",
            "1358\n",
            "2000\n",
            "1431\n",
            "2100\n",
            "1504\n",
            "2200\n",
            "1582\n",
            "2300\n",
            "1658\n",
            "2400\n",
            "1732\n",
            "2500\n",
            "1800\n",
            "2600\n",
            "1877\n",
            "2700\n",
            "1947\n",
            "2800\n",
            "2024\n",
            "2900\n",
            "2097\n",
            "3000\n",
            "2173\n",
            "3100\n",
            "2244\n",
            "3200\n",
            "2321\n",
            "3300\n",
            "2394\n",
            "3400\n",
            "2474\n",
            "3500\n",
            "2548\n",
            "3600\n",
            "2621\n",
            "3700\n",
            "2702\n",
            "3800\n",
            "2784\n",
            "3900\n",
            "2861\n",
            "4000\n",
            "2942\n",
            "4100\n",
            "3015\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#from data_loader import *\n",
        "#from embeddings import *\n",
        "#from layers_attempt import *\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang, max_length=100):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        if torch.cuda.is_available():\n",
        "            input_tensor = input_tensor.cuda()\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden1 = torch.zeros(encoder.layers, 1, encoder.hidden_size, device=device)\n",
        "        encoder_hidden2 = torch.zeros(encoder.layers, 1, encoder.hidden_size, device=device)\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, (encoder_hidden1, encoder_hidden2) = encoder(input_tensor[ei],\n",
        "                                                     (encoder_hidden1, encoder_hidden2))\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "        decoder_hidden1 = encoder_hidden1\n",
        "        decoder_hidden2 = encoder_hidden2\n",
        "\n",
        "        decoded_words = []\n",
        "        for di in range(max_length):\n",
        "            decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2))\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                #decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "        return decoded_words\n",
        "\n",
        "def evaluateIters(test_data, encoder, decoder, lang_in, lang_out):\n",
        "    hit = 0\n",
        "    miss = 0\n",
        "    iters = 0\n",
        "    hit_idx = []\n",
        "    miss_idx = []\n",
        "\n",
        "    for idx, test_point in enumerate(test_data):\n",
        "        pred = evaluate(encoder, decoder, test_point[0], lang_in, lang_out)\n",
        "        pred = \" \".join(pred)\n",
        "        if pred == test_point[1]:\n",
        "            hit += 1\n",
        "            hit_idx.append(idx)\n",
        "        else:\n",
        "            miss += 1\n",
        "            miss_idx.append(idx)\n",
        "        iters += 1\n",
        "\n",
        "        if iters % 100 == 0:\n",
        "            print(iters)\n",
        "            print(hit)\n",
        "\n",
        "    return hit, hit_idx, miss, miss_idx\n",
        "\n",
        "hit, hit_idx, miss, miss_idx = evaluateIters(test_data, encoder, decoder, train_in, train_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "9auy0X5hXmD8",
        "outputId": "1b0752d4-768d-4832-998c-0f78079afa5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT'"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\" \".join(evaluate(encoder, decoder, test_data[4000][0], train_in, train_out)) #3742"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "EG638DGIa-je",
        "outputId": "2ef8e446-d0c6-4e9e-df70-9386e416b213"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'turn left thrice after turn opposite right twice'"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[4000][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "OFn0WQ1kU0VG",
        "outputId": "bd34bec0-3b01-4241-9f7a-1ceb74ab466c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max([len(x[0].split()) for x in train_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jJcgD6Z4VaFS"
      },
      "outputs": [],
      "source": []
    }
  ]
}