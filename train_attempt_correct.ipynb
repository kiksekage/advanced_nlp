{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_attempt_correct.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "colab_type": "code",
        "id": "5Z-O16QDJqpV",
        "outputId": "65eac975-b9bd-46ec-8fa1-aba566b7f447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yJiVsQSFJqpk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, filepath):\n",
        "        cwd = os.getcwd()\n",
        "        self.basepath = filepath\n",
        "        try:\n",
        "            os.stat(self.basepath+\"/add_prim_split\")\n",
        "            os.stat(self.basepath+\"/few_shot_split\")\n",
        "            os.stat(self.basepath+\"/filler_split\")\n",
        "            os.stat(self.basepath+\"/length_split\")\n",
        "            os.stat(self.basepath+\"/simple_split\")\n",
        "            os.stat(self.basepath+\"/template_split\")\n",
        "        except Exception as e:\n",
        "            raise Exception(\"Path \"+filepath+\" doesnt seem to contain the required folders.\")\n",
        "\n",
        "    def load_1a(self):\n",
        "        train = self.file_loader(\"/simple_split/tasks_train_simple.txt\")\n",
        "        test = self.file_loader(\"/simple_split/tasks_test_simple.txt\")\n",
        "\n",
        "        return (np.asarray(train), np.asarray(test))\n",
        "\n",
        "    def load_1b(self):\n",
        "        percentile_dict = {}\n",
        "        splits = [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\"]\n",
        "\n",
        "        for percentile in splits:\n",
        "            train = self.file_loader(\"/simple_split/size_variations/tasks_train_simple_p{}.txt\".format(percentile))\n",
        "            test = self.file_loader(\"/simple_split/size_variations/tasks_test_simple_p{}.txt\".format(percentile))\n",
        "            \n",
        "            percentile_dict[percentile] = (np.asarray(train), np.asarray(test))\n",
        "            \n",
        "        return percentile_dict\n",
        "\n",
        "    def load_2(self):\n",
        "        train = self.file_loader(\"/length_split/tasks_train_length.txt\")\n",
        "        test = self.file_loader(\"/length_split/tasks_test_length.txt\")\n",
        "\n",
        "        return (np.asarray(train), np.asarray(test))\n",
        "\n",
        "    def load_3(self):\n",
        "        \"\"\"\n",
        "        loads the datasets for both parts of the experiment\n",
        "        the first part where both primitives appear without compositional commands\n",
        "        the second part where 'jump' primitive appears in\n",
        "        compositional commands of varying lengths\n",
        "        returns a dictionary of pairs all possible train/test sets\n",
        "        \"\"\"\n",
        "        data_dict = {}\n",
        "        nums = [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\"]\n",
        "        reps = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "        train = self.file_loader(\"/add_prim_split/tasks_train_addprim_jump.txt\")\n",
        "        test = self.file_loader(\"/add_prim_split/tasks_test_addprim_jump.txt\")\n",
        "        data_dict['jump'] = (np.asarray(train), np.asarray(test))\n",
        "\n",
        "        train = self.file_loader(\"/add_prim_split/tasks_train_addprim_turn_left.txt\")\n",
        "        test = self.file_loader(\"/add_prim_split/tasks_test_addprim_turn_left.txt\")\n",
        "        data_dict['lturn'] = (np.asarray(train), np.asarray(test))\n",
        "        \n",
        "        for num in nums:\n",
        "            for rep in reps:\n",
        "                train = self.file_loader(\"/add_prim_split/with_additional_examples/tasks_train_addprim_complex_jump_num{}_rep{}.txt\".format(num, rep))\n",
        "                test = self.file_loader(\"/add_prim_split/with_additional_examples/tasks_test_addprim_complex_jump_num{}_rep{}.txt\".format(num, rep))\n",
        "                \n",
        "                data_dict['jump_num{}_rep{}'.format(num, rep)] = (np.asarray(train), np.asarray(test))\n",
        "            \n",
        "        return data_dict\n",
        "\n",
        "    def file_loader(self, path):\n",
        "        sent_list = []\n",
        "        with open(self.basepath+path, \"r\") as f:\n",
        "                    for line in f:\n",
        "                        sent_list.append(line_splitter(line))\n",
        "        return sent_list\n",
        "\n",
        "    \n",
        "def line_splitter(sentence):\n",
        "    sent_list = sentence.split(\"OUT: \")\n",
        "    sent_list[0] = sent_list[0].strip(\"IN: \")\n",
        "    sent_list[1] = sent_list[1].strip(\"\\n\")\n",
        "\n",
        "    return sent_list\n",
        "\n",
        "# examples:\n",
        "# 1a :\n",
        "#   train, test = dl.load_1a()\n",
        "#   train[0][0] first train sentence, \"IN\"\n",
        "#   train[0][1] first train sentence, \"OUT\"\n",
        "# 1b :\n",
        "#   dict = dl.load_1b()\n",
        "#   train, test = dict[\"1\"] extract the 1 percentile sentences out, split into train and test\n",
        "#   train[0][0] first train sentence, \"OUT\"\n",
        "#   train[0][1] first train sentence, \"OUT\"\n",
        "#\n",
        "# all returns are numpy arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "whB7XHBzJqps"
      },
      "outputs": [],
      "source": [
        "#from data_loader import DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Input:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {EOS_token: \"EOS\"}\n",
        "        #self.index2word = {}\n",
        "        self.n_words = 1  # Count SOS and EOS\n",
        "        #self.n_words = 0\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "class Output:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        #self.index2word = {}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "        #self.n_words = 0\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "\n",
        "        \n",
        "def get_embedding(word, lookup_dict, embeds):\n",
        "    tensor = torch.tensor([lookup_dict[word]], dtype=torch.long)\n",
        "    return embeds(tensor)\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair, input_lang, output_lang):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, output_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FZ1BIiplJqpy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#from data_loader import *\n",
        "#from embeddings import *\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class CustomLoss(torch.autograd.Function):  \n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        import ipdb; ipdb.set_trace()\n",
        "        #pass\n",
        "        return\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.0, layers=1, mode='RNN'):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.layers = layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        self.hidden_layer = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "        if mode == 'LSTM':\n",
        "        \tself.hidden_layer = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        elif mode == 'GRU':\n",
        "        \tself.hidden_layer = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        output, hidden = self.hidden_layer(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(self.layers, 1, self.hidden_size, device=device)\n",
        "        nn.init.xavier_uniform_(hidden, gain=nn.init.calculate_gain('relu'))\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, max_length, dropout_p=0.0, layers=1, attention=False, mode='RNN'):\n",
        "    \t#layers should be either 1 or 2\n",
        "    \t#in the latter case remember to pass a pair of hidden states!\n",
        "    \t#mode can be either 'LSTM', 'GRU' or 'RNN'\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.layers = layers\n",
        "        self.max_length = max_length\n",
        "        self.attention = attention\n",
        "        self.mode = mode\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        if self.attention:\n",
        "\t        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "\t        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "\n",
        "        self.hidden_layer = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "        if mode == 'LSTM':\n",
        "        \tself.hidden_layer = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        elif mode == 'GRU':\n",
        "        \tself.hidden_layer = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs=None):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if self.attention:\n",
        "\t        attn_weights = F.softmax(\n",
        "\t            self.attn(torch.cat((output[0], hidden[0]), 1)), dim=1)\n",
        "\t        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "\t                                 encoder_outputs.unsqueeze(0))\n",
        "\t        output = torch.cat((output[0], attn_applied[0]), 1)\n",
        "        \toutput = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.hidden_layer(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(self.layers, 1, self.hidden_size, device=device)\n",
        "        nn.init.xavier_uniform_(hidden, gain=nn.init.calculate_gain('relu'))\n",
        "        return hidden\n",
        "\n",
        "def train(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, clipping_value=5, mode='RNN'):\n",
        "    encoder_hidden1 = encoder.initHidden()\n",
        "    encoder_hidden2 = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    output_length = output_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        if mode == 'LSTM':\n",
        "            encoder_output, (encoder_hidden1, encoder_hidden2) = encoder(input_tensor[ei], (encoder_hidden1, encoder_hidden2))\n",
        "        else: \n",
        "            encoder_output, encoder_hidden1 = encoder(input_tensor[ei], encoder_hidden1)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden1 = encoder_hidden1\n",
        "    decoder_hidden2 = encoder_hidden2\n",
        "\n",
        "    forcing = random.random() > 0.5\n",
        "\n",
        "    if forcing:\n",
        "        for di in range(output_length):\n",
        "            if mode == 'LSTM':\n",
        "                decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2), encoder_outputs)\n",
        "            else:\n",
        "                decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden1, encoder_outputs)\n",
        "            decoder_input = output_tensor[di]\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "    else:\n",
        "        for di in range(output_length):\n",
        "            if mode == 'LSTM':\n",
        "                decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2), encoder_outputs)\n",
        "            else:\n",
        "                decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden1, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "            \n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    #loss = CustomLoss\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clipping_value)\n",
        "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clipping_value)\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.item() / output_length\n",
        "\n",
        "    \n",
        "def trainIters(encoder, decoder, train_data, input_lang, output_lang, max_length, learning_rate=0.001, mode='RNN'):\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    losses = []\n",
        "    print(train_data.shape[0])\n",
        "    print_loss_total = 0\n",
        "\n",
        "    for iter in range(train_data.shape[0]):\n",
        "        training_pair = tensorsFromPair(train_data[iter], input_lang, output_lang)\n",
        "        input_tensor = training_pair[0]\n",
        "        output_tensor = training_pair[1]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            input_tensor = input_tensor.cuda()\n",
        "            output_tensor = output_tensor.cuda()\n",
        "        \n",
        "        loss = train(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, mode=mode)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            print_loss_avg = print_loss_total / 500\n",
        "            losses.append(print_loss_avg)\n",
        "            print(iter)\n",
        "            print(print_loss_avg)\n",
        "            print_loss_total = 0\n",
        "\n",
        "    return losses\n",
        "\n",
        "dl = DataLoader(\"/content/drive/My Drive/SCAN\")\n",
        "#dl = DataLoader(\"SCAN\")\n",
        "train_data, test_data = dl.load_1a()\n",
        "\n",
        "MAX_LENGTH = max([len(x[0].split()) for x in train_data]) + 1\n",
        "\n",
        "train_in = Input(\"train_input\")\n",
        "train_out = Output(\"train_output\")\n",
        "\n",
        "test_in = Input(\"test_input\")\n",
        "test_out = Output(\"test_output\")\n",
        "\n",
        "for datapoint in train_data:\n",
        "        train_in.addSentence(datapoint[0])\n",
        "        train_out.addSentence(datapoint[1])\n",
        "\n",
        "for datapoint in test_data:\n",
        "        test_in.addSentence(datapoint[0])\n",
        "        test_out.addSentence(datapoint[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "66NZZ_dOKUg9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "\n",
        "train_data = train_data[np.random.choice(train_data.shape[0], 100000, replace=True), :]\n",
        "\n",
        "def train_and_save(model, dropout, att, layers, model_name):\n",
        "    encoder = Encoder(train_in.n_words, 200, layers=layers, mode=model, dropout_p=dropout)\n",
        "    decoder = Decoder(200, train_out.n_words, layers=layers, max_length=MAX_LENGTH, mode=model, dropout_p=dropout, attention=att)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        encoder.cuda()\n",
        "        decoder.cuda()\n",
        "\n",
        "    losses = trainIters(encoder, decoder, train_data, train_in, train_out, MAX_LENGTH, mode=model)\n",
        "    plt.plot(losses)\n",
        "    plt.title(model+'_layers='+str(layers)+'_drop='+str(dropout)+'_attention='+str(att))\n",
        "    plt.xlabel('iterations')\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()\n",
        "    torch.save(encoder.state_dict(), \"/content/drive/My Drive/\"+model_name+\"_encoder.pt\")\n",
        "    torch.save(decoder.state_dict(), \"/content/drive/My Drive/\"+model_name+\"_decoder.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "NwGTOeF7Jqp6",
        "outputId": "1640e1e1-2f2c-4f87-f3e5-1b94612fc5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100000\n",
            "0\n",
            "0.004119700961642795\n",
            "500\n",
            "1.5949168662321818\n",
            "1000\n",
            "1.4709285796638725\n",
            "1500\n",
            "1.3343626668061999\n",
            "2000\n",
            "1.272541236425822\n",
            "2500\n",
            "1.187393005743957\n",
            "3000\n",
            "1.1485692007879087\n",
            "3500\n",
            "1.126983015876954\n",
            "4000\n",
            "1.0740889182438413\n",
            "4500\n",
            "0.9841023738097732\n",
            "5000\n",
            "0.9747410960309113\n",
            "5500\n",
            "0.981141370982573\n",
            "6000\n",
            "0.9054860147283753\n",
            "6500\n",
            "0.9015401197767735\n",
            "7000\n",
            "0.90154403069625\n",
            "7500\n",
            "0.8705523979803783\n",
            "8000\n",
            "0.8762847055603105\n",
            "8500\n",
            "0.8537530820929674\n",
            "9000\n",
            "0.805200982202835\n",
            "9500\n",
            "0.857516899644759\n",
            "10000\n",
            "0.7930936195546444\n",
            "10500\n",
            "0.7942201201226358\n",
            "11000\n",
            "0.8230595802447029\n",
            "11500\n",
            "0.8207084129672462\n",
            "12000\n",
            "0.7550211419546977\n",
            "12500\n",
            "0.7718556569424956\n",
            "13000\n",
            "0.7536491048786875\n",
            "13500\n",
            "0.7793434436751285\n",
            "14000\n",
            "0.7169751009610632\n",
            "14500\n",
            "0.7564934038396404\n",
            "15000\n",
            "0.7794855287281695\n",
            "15500\n",
            "0.7075503241201979\n",
            "16000\n",
            "0.7285597370284049\n",
            "16500\n",
            "0.7294726516426889\n",
            "17000\n",
            "0.7565476751616295\n",
            "17500\n",
            "0.7023099289978052\n",
            "18000\n",
            "0.6964265908255417\n",
            "18500\n",
            "0.7643266276090654\n",
            "19000\n",
            "0.6933547171906643\n",
            "19500\n",
            "0.7344704066900655\n",
            "20000\n",
            "0.7553085725187172\n",
            "20500\n",
            "0.7621379455431326\n",
            "21000\n",
            "0.7508137564695904\n",
            "21500\n",
            "0.7725302453782218\n",
            "22000\n",
            "0.73824126858655\n",
            "22500\n",
            "0.6871791719622108\n",
            "23000\n",
            "0.6880456877461779\n",
            "23500\n",
            "0.6797615865739035\n",
            "24000\n",
            "0.7078602688723774\n",
            "24500\n",
            "0.703401963627371\n",
            "25000\n",
            "0.6990203106338518\n",
            "25500\n",
            "0.6853424212249791\n",
            "26000\n",
            "0.7546501863499088\n",
            "26500\n",
            "0.6898476677313579\n",
            "27000\n",
            "0.652297691724775\n",
            "27500\n",
            "0.6990712140175468\n",
            "28000\n",
            "0.7708246822326342\n",
            "28500\n",
            "0.6556307679932878\n",
            "29000\n",
            "0.7493586000628065\n",
            "29500\n",
            "0.6768036321777532\n",
            "30000\n",
            "0.6638350646932136\n",
            "30500\n",
            "0.7288548333446323\n",
            "31000\n",
            "0.6504956731282024\n",
            "31500\n",
            "0.6941211661667716\n",
            "32000\n",
            "0.71132757921486\n",
            "32500\n",
            "0.6907821402107633\n",
            "33000\n",
            "0.6771640539990749\n",
            "33500\n",
            "0.7395939004458016\n",
            "34000\n",
            "0.7429848229993898\n",
            "34500\n",
            "0.6759563301607697\n",
            "35000\n",
            "0.7162918207846423\n",
            "35500\n",
            "0.7067043900088472\n",
            "36000\n",
            "0.7465293138316873\n",
            "36500\n",
            "0.7079087400974361\n",
            "37000\n",
            "0.6815914880591813\n",
            "37500\n",
            "0.6789344413255528\n",
            "38000\n",
            "0.6964334161306297\n",
            "38500\n",
            "0.6827988916592811\n",
            "39000\n",
            "0.7035199158607817\n",
            "39500\n",
            "0.7286565801576002\n",
            "40000\n",
            "0.667725287065898\n",
            "40500\n",
            "0.6574821426255599\n",
            "41000\n",
            "0.6985622200539993\n",
            "41500\n",
            "0.6791700726993971\n",
            "42000\n",
            "0.6742448523677279\n",
            "42500\n",
            "0.7190606376235812\n",
            "43000\n",
            "0.6961128168264492\n",
            "43500\n",
            "0.6751703791296838\n",
            "44000\n",
            "0.6919612738453118\n",
            "44500\n",
            "0.6528385574374868\n",
            "45000\n",
            "0.6712952113954388\n",
            "45500\n",
            "0.6483479861525113\n",
            "46000\n",
            "0.6278674602680208\n",
            "46500\n",
            "0.6617004299256428\n",
            "47000\n",
            "0.6584489750898316\n",
            "47500\n",
            "0.6824385223872466\n",
            "48000\n",
            "0.6754090733906508\n",
            "48500\n",
            "0.6852275115683868\n",
            "49000\n",
            "0.7417840097266667\n",
            "49500\n",
            "0.6519268024031969\n",
            "50000\n",
            "0.6620400284285521\n",
            "50500\n",
            "0.6501779757744012\n",
            "51000\n",
            "0.6910456713283812\n",
            "51500\n",
            "0.7218751108998994\n",
            "52000\n",
            "0.7714259010250022\n",
            "52500\n",
            "0.690187489744253\n",
            "53000\n",
            "0.7299023677013096\n",
            "53500\n",
            "0.7378151659667515\n",
            "54000\n",
            "0.6784623292361306\n",
            "54500\n",
            "0.648664690781972\n",
            "55000\n",
            "0.6740586561931524\n",
            "55500\n",
            "0.7324119065835999\n",
            "56000\n",
            "0.6805905525038065\n",
            "56500\n",
            "0.7299311409179515\n",
            "57000\n",
            "0.7049585106782513\n",
            "57500\n",
            "0.7122446129571103\n",
            "58000\n",
            "0.7318784219697247\n",
            "58500\n",
            "0.7218886677059826\n",
            "59000\n",
            "0.6804425969337263\n",
            "59500\n",
            "0.6790519779756814\n",
            "60000\n",
            "0.6964673880426177\n",
            "60500\n",
            "0.7722477168942808\n",
            "61000\n",
            "0.7465140828402439\n",
            "61500\n",
            "0.7645119789711338\n",
            "62000\n",
            "0.6655347570285726\n",
            "62500\n",
            "0.7057061670980495\n",
            "63000\n",
            "0.7383022102204497\n",
            "63500\n",
            "0.8188265825993478\n",
            "64000\n",
            "0.7055102068208753\n",
            "64500\n",
            "0.701522567831243\n",
            "65000\n",
            "0.6642411505580469\n",
            "65500\n",
            "0.7228925722398292\n",
            "66000\n",
            "0.6909988276241874\n",
            "66500\n",
            "0.727542505539513\n",
            "67000\n",
            "0.8237704334400283\n",
            "67500\n",
            "0.7841200959150983\n",
            "68000\n",
            "0.7418988942248315\n",
            "68500\n",
            "0.7895835612244576\n",
            "69000\n",
            "0.7784775403274371\n",
            "69500\n",
            "0.776875900732806\n",
            "70000\n",
            "0.7582261731008494\n",
            "70500\n",
            "0.750869430880728\n",
            "71000\n",
            "0.7458421578723023\n",
            "71500\n",
            "0.773902283782835\n",
            "72000\n",
            "0.7634700788607063\n",
            "72500\n",
            "0.750377459172021\n",
            "73000\n",
            "0.7765556339788424\n",
            "73500\n",
            "0.7080749811748894\n",
            "74000\n",
            "0.7873849306172876\n",
            "74500\n",
            "0.7714824068017471\n",
            "75000\n",
            "0.728160819797544\n",
            "75500\n",
            "0.775798852086555\n",
            "76000\n",
            "0.7649715645013976\n",
            "76500\n",
            "0.715971686526136\n",
            "77000\n",
            "0.68910469995889\n",
            "77500\n",
            "0.7655459352317556\n",
            "78000\n",
            "0.7217980326513657\n",
            "78500\n",
            "0.75442538131751\n",
            "79000\n",
            "0.7323913684582015\n",
            "79500\n",
            "0.7265242183068101\n",
            "80000\n",
            "0.7259647269885581\n",
            "80500\n",
            "0.7020647419023455\n",
            "81000\n",
            "0.787242467022409\n",
            "81500\n",
            "0.8026480654626778\n",
            "82000\n",
            "0.695314815574946\n",
            "82500\n",
            "0.7373038758464856\n",
            "83000\n",
            "0.7890213980805478\n",
            "83500\n",
            "0.7870336721081976\n",
            "84000\n",
            "0.7660968360320275\n",
            "84500\n",
            "0.7461165191138537\n",
            "85000\n",
            "0.7171245609851372\n",
            "85500\n",
            "0.7616823252955905\n",
            "86000\n",
            "0.7403329410996445\n",
            "86500\n",
            "0.8022973708456032\n",
            "87000\n",
            "0.7140151251482744\n",
            "87500\n",
            "0.7780513465991771\n",
            "88000\n",
            "0.7595407284078005\n",
            "88500\n",
            "0.7808158503961039\n",
            "89000\n",
            "0.8216607023147441\n",
            "89500\n",
            "0.784771208566012\n",
            "90000\n",
            "0.7741124360252956\n",
            "90500\n",
            "0.8074163102255342\n",
            "91000\n",
            "0.7919516018478628\n",
            "91500\n",
            "0.7841508788367083\n",
            "92000\n",
            "0.7714541535011546\n",
            "92500\n",
            "0.8098043963009606\n",
            "93000\n",
            "0.7749839651098678\n",
            "93500\n",
            "0.782504269771749\n",
            "94000\n",
            "0.857222799317229\n",
            "94500\n",
            "0.8473744349880573\n",
            "95000\n",
            "0.8213668440067067\n",
            "95500\n",
            "0.7992189082347129\n",
            "96000\n",
            "0.7982028625564223\n",
            "96500\n",
            "0.8007831031332509\n",
            "97000\n",
            "0.8030752874935435\n",
            "97500\n",
            "0.7847275519787748\n",
            "98000\n",
            "0.8140103285534429\n",
            "98500\n",
            "0.785538174070599\n",
            "99000\n",
            "0.7801528664026777\n",
            "99500\n",
            "0.7949113223822786\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAGDCAYAAAAGfDUgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhitJkqSCvgCj6exE59uR4QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100000\n",
            "0\n",
            "0.004250081804063585\n",
            "500\n",
            "1.6368295635267123\n",
            "1000\n",
            "1.4744429049435845\n",
            "1500\n",
            "1.4258974091330323\n",
            "2000\n",
            "1.410977292054672\n",
            "2500\n",
            "1.3453932688258634\n",
            "3000\n",
            "1.3674984625123032\n",
            "3500\n",
            "1.3153434303021103\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b82cfcdf1557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RNN'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'srn_att_drop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'srn_att_drop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'srn_att_drop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-f5c1f6ce1876>\u001b[0m in \u001b[0;36mtrain_and_save\u001b[0;34m(model, dropout, att, layers, model_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_layers='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_drop='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_attention='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-ca177b5507dd>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, train_data, input_lang, output_lang, max_length, learning_rate, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-ca177b5507dd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, clipping_value, mode)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m#loss = CustomLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipping_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model='RNN'\n",
        "train_and_save(model, 0.5, True, 2, 'srn_att_drop')\n",
        "train_and_save(model, 0.0, False, 2, 'srn_att_drop')\n",
        "train_and_save(model, 0.0, True, 2, 'srn_att_drop')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "pxmS4rEHL366",
        "outputId": "7c144b71-43bf-454f-a369-df7b5bb776e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "62\n",
            "200\n",
            "132\n",
            "300\n",
            "205\n",
            "400\n",
            "275\n",
            "500\n",
            "342\n",
            "600\n",
            "414\n",
            "700\n",
            "481\n",
            "800\n",
            "552\n",
            "900\n",
            "627\n",
            "1000\n",
            "705\n",
            "1100\n",
            "781\n",
            "1200\n",
            "845\n",
            "1300\n",
            "920\n",
            "1400\n",
            "990\n",
            "1500\n",
            "1068\n",
            "1600\n",
            "1136\n",
            "1700\n",
            "1213\n",
            "1800\n",
            "1282\n",
            "1900\n",
            "1358\n",
            "2000\n",
            "1431\n",
            "2100\n",
            "1504\n",
            "2200\n",
            "1582\n",
            "2300\n",
            "1658\n",
            "2400\n",
            "1732\n",
            "2500\n",
            "1800\n",
            "2600\n",
            "1877\n",
            "2700\n",
            "1947\n",
            "2800\n",
            "2024\n",
            "2900\n",
            "2097\n",
            "3000\n",
            "2173\n",
            "3100\n",
            "2244\n",
            "3200\n",
            "2321\n",
            "3300\n",
            "2394\n",
            "3400\n",
            "2474\n",
            "3500\n",
            "2548\n",
            "3600\n",
            "2621\n",
            "3700\n",
            "2702\n",
            "3800\n",
            "2784\n",
            "3900\n",
            "2861\n",
            "4000\n",
            "2942\n",
            "4100\n",
            "3015\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#from data_loader import *\n",
        "#from embeddings import *\n",
        "#from layers_attempt import *\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang, max_length=100):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        if torch.cuda.is_available():\n",
        "            input_tensor = input_tensor.cuda()\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden1 = torch.zeros(encoder.layers, 1, encoder.hidden_size, device=device)\n",
        "        encoder_hidden2 = torch.zeros(encoder.layers, 1, encoder.hidden_size, device=device)\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, (encoder_hidden1, encoder_hidden2) = encoder(input_tensor[ei],\n",
        "                                                     (encoder_hidden1, encoder_hidden2))\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "        decoder_hidden1 = encoder_hidden1\n",
        "        decoder_hidden2 = encoder_hidden2\n",
        "\n",
        "        decoded_words = []\n",
        "        for di in range(max_length):\n",
        "            decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2))\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                #decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "        return decoded_words\n",
        "\n",
        "def evaluateIters(test_data, encoder, decoder, lang_in, lang_out):\n",
        "    hit = 0\n",
        "    miss = 0\n",
        "    iters = 0\n",
        "    hit_idx = []\n",
        "    miss_idx = []\n",
        "\n",
        "    for idx, test_point in enumerate(test_data):\n",
        "        pred = evaluate(encoder, decoder, test_point[0], lang_in, lang_out)\n",
        "        pred = \" \".join(pred)\n",
        "        if pred == test_point[1]:\n",
        "            hit += 1\n",
        "            hit_idx.append(idx)\n",
        "        else:\n",
        "            miss += 1\n",
        "            miss_idx.append(idx)\n",
        "        iters += 1\n",
        "\n",
        "        if iters % 100 == 0:\n",
        "            print(iters)\n",
        "            print(hit)\n",
        "\n",
        "    return hit, hit_idx, miss, miss_idx\n",
        "\n",
        "hit, hit_idx, miss, miss_idx = evaluateIters(test_data, encoder, decoder, train_in, train_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "10WjnZrGR8aD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "9auy0X5hXmD8",
        "outputId": "1b0752d4-768d-4832-998c-0f78079afa5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT'"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\" \".join(evaluate(encoder, decoder, test_data[4000][0], train_in, train_out)) #3742"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "EG638DGIa-je",
        "outputId": "2ef8e446-d0c6-4e9e-df70-9386e416b213"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'turn left thrice after turn opposite right twice'"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[4000][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "OFn0WQ1kU0VG",
        "outputId": "bd34bec0-3b01-4241-9f7a-1ceb74ab466c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max([len(x[0].split()) for x in train_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "jJcgD6Z4VaFS",
        "outputId": "6e46323f-ccbf-4240-83b7-83c8762c3ec1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'True'"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sSWSsqUHS3Rc"
      },
      "outputs": [],
      "source": []
    }
  ]
}